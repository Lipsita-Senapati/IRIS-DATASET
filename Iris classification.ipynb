{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRIS CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pylab import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "iris = pd.read_csv(r'C:\\Users\\LIPSITA_SENAPATI\\Flower-Prediction\\Iris.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display few of the data\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input labels and output\n",
    "X = iris.iloc[:,1:5] # ignore first column which is row Id\n",
    "y = iris.iloc[:,5:6] # Classification on the 'Species'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing train and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.94\n",
      "Accuracy of Logistic regression classifier on test set: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train,y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(logreg.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(logreg.score(X_test, y_test)))\n",
    "y_pred=logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic regression classifier on training set: 0.94\n",
      "Accuracy of Logistic regression classifier on test set: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "mul_lr = LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(X_train, y_train)\n",
    "mul_lr.fit(X_train, y_train)\n",
    "print('Accuracy of Logistic regression classifier on training set: {:.2f}'\n",
    "     .format(mul_lr.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic regression classifier on test set: {:.2f}'\n",
    "     .format(mul_lr.score(X_test, y_test)))\n",
    "y_pred=mul_lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.94      1.00      0.97        15\n",
      " Iris-virginica       1.00      0.96      0.98        23\n",
      "\n",
      "       accuracy                           0.98        60\n",
      "      macro avg       0.98      0.99      0.98        60\n",
      "   weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 1.00\n",
      "Accuracy of Decision Tree classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "     .format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of Decision Tree classifier on test set: {:.2f}'\n",
    "     .format(clf.score(X_test, y_test)))\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.93      0.93      0.93        15\n",
      " Iris-virginica       0.96      0.96      0.96        23\n",
      "\n",
      "       accuracy                           0.97        60\n",
      "      macro avg       0.96      0.96      0.96        60\n",
      "   weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K- Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.96\n",
      "Accuracy of K-NN classifier on test set: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "print('Accuracy of K-NN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of K-NN classifier on test set: {:.2f}'\n",
    "     .format(knn.score(X_test, y_test)))\n",
    "y_pred=knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.94      1.00      0.97        15\n",
      " Iris-virginica       1.00      0.96      0.98        23\n",
      "\n",
      "       accuracy                           0.98        60\n",
      "      macro avg       0.98      0.99      0.98        60\n",
      "   weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LDA classifier on training set: 0.97\n",
      "Accuracy of LDA classifier on test set: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n",
    "print('Accuracy of LDA classifier on training set: {:.2f}'\n",
    "     .format(lda.score(X_train, y_train)))\n",
    "print('Accuracy of LDA classifier on test set: {:.2f}'\n",
    "     .format(lda.score(X_test, y_test)))\n",
    "y_pred=lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       1.00      1.00      1.00        15\n",
      " Iris-virginica       1.00      1.00      1.00        23\n",
      "\n",
      "       accuracy                           1.00        60\n",
      "      macro avg       1.00      1.00      1.00        60\n",
      "   weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GNB classifier on training set: 0.96\n",
      "Accuracy of GNB classifier on test set: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "print('Accuracy of GNB classifier on training set: {:.2f}'\n",
    "     .format(gnb.score(X_train, y_train)))\n",
    "print('Accuracy of GNB classifier on test set: {:.2f}'\n",
    "     .format(gnb.score(X_test, y_test)))\n",
    "y_pred=gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       0.93      0.93      0.93        15\n",
      " Iris-virginica       0.96      0.96      0.96        23\n",
      "\n",
      "       accuracy                           0.97        60\n",
      "      macro avg       0.96      0.96      0.96        60\n",
      "   weighted avg       0.97      0.97      0.97        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier on training set: 0.96\n",
      "Accuracy of SVM classifier on test set: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\lipsita_senapati\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "print('Accuracy of SVM classifier on training set: {:.2f}'\n",
    "     .format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of SVM classifier on test set: {:.2f}'\n",
    "     .format(svm.score(X_test, y_test)))\n",
    "y_pred=svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        22\n",
      "Iris-versicolor       1.00      1.00      1.00        15\n",
      " Iris-virginica       1.00      1.00      1.00        23\n",
      "\n",
      "       accuracy                           1.00        60\n",
      "      macro avg       1.00      1.00      1.00        60\n",
      "   weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22,  0,  0],\n",
       "       [ 0, 15,  0],\n",
       "       [ 0,  0, 23]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "class_names=[0,1,2] # name  of classes\n",
    "fig, ax = plt.subplots()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "# create heatmap\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\")\n",
    "plt.tight_layout()\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "Text(0.5,257.44,'Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
